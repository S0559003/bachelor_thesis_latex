\chapter{Grundlagen}

Dieses Kapitel gibt ein Überblick über die in dieser Arbeit verwendete Terminologien und führt in Grundlagen zu Technologien und Techniken ein welche die Basis für dieser Arbeit bilden. 

Nachdem die Definition von Augumented Reality erläutert wurde, werden unterschiedliche Ansätze für die Objekterkennung und Verfolgung vorgestellt.  Diese bilden einen essenzieller Bestandteil von Augumented Reality.  
Es wird die die Definition von situationsbezogener Visualisierung (en. Situated Visualization) erläutert und Visualisierungstechniken für die Darstellung von Daten im Kontext zur physischen Welt (z. Bsp. Gegenstände, Person,  Aufgabe) vorgestellt. 
Abschließend wird die Definition von Usability näher gebracht und  ein Einblick in Usablity Engineering gegeben welches  eine etablierte Vorgehensweise für die Gestaltung und  Entwicklung von Systemen hohen Usability Anforderungen ist. 

% AR, Traking Methoden, Situative Visualisierung, Kommunikation, Usability Usability Engenieering als Methode,Open Innovation 

\section{Augmented Reality}

%Definition und Begriffseingrenzung  von AR
Augmented Reality (zu dt. Erweiterte Realität, kurz AR) steht für das Überlagern der realen Welt mit digitalen Informationen. \cite{Azuma.1997,DieterSchmalstieg2016} Im Gegensatz zu virtuellen Realität wo Benutzer vollständig in virtuelle Umgebungen eintauchen,
ist das Ziel von AR, Informationen direkt in die physische Umgebung des Benutzers einzufügen. So soll der Eindruck entstehen, dass diese Informationen Teil der realen Welt sind. \footnote[1]{ Laut Definition von Azuma  müssen Informationen hierbei nicht nur auf visuelle Informationen beschränkt sein, 
sondern können auch auditive, haptische, gustative (Geschmack) oder auch olfaktorisch (Geruch) Informationen beinhalten.} \cite{Azuma.1997} Während in VR, Benutzer von der äußeren Umgebung nichts mitbekommen, wird in AR die reale Umgebung des Benutzers, mit vitruellen 
Objekten überlagert. Azuma beschreibt in \cite{Azuma.1997}, folgende Charakteristiken für Augmented Reality: 

\begin{enumerate}
	\item Kombinieren reale und virtuelle Welt (Combines real and virtual).
	\item Ermöglichen Interaktionen in Echtzeit. (Interactive in real time)
	\item Informationen (reale und virtuelle) haben einen Bezug im dreidimensionalen Raum. (Registered in 3-D)
\end{enumerate}

Diese Charakteristiken helfen dabei den Augmented Reality besser einzugrenzen. \cite{Azuma.1997} Filme wie z. Bsp. ``Jurassic Park", in welchen virtuelle Objekte in die reale Szene eingefügt werden, 
erwecken zwar den Eindruck dass diese Objekte, Teil der realen Szene sind, jedoch kann mit diesen Objekten nicht in Echtzeit interagiert werden. \cite{Tonnis2010} In Filmen werden die virtuellen Objekte in eine zuvor aufgezeichnete Aufnahme eingefügt. 
Im Gegensatz werden diese, in AR in ein live Video eingefügt. Dies bedeutet dass in  Filmen für das Einfügen von digitalen Informationen in die reale Szene eine viel größere Zeit zur Verfügung steht. In AR muss dies in wenigen Millisekunden geschehen. 
Die neue Position und Ausrichtung des virtuellen Objektes in live Szene muss in der Zeit zwischen zwei Frames bestimmt werden.

Ein anderes Beispiel im Live Ansicht von Digitalkameras zu finden, welche das aufzunehmende Bild als Vorschau anzeigen. Oft blenden Digitalkameras Informationen zu den aktuellen Einstellungen der Kamera sowie den Ladezustand der Batterie im Vorschaubild ein (Siehe Abbildung \ref{img:ar_camera_example}).  
Diese Informationen überlagern zwar die reale Szene, haben jedoch keinen Bezug zum dreidimensionalen Raum. Der elektronische Sucher hingegen welches Objekte (z. Bsp. Gesichter) erkennt und in einem virtuellen Rahmen einrahmt, hat ein Bezug zu den Objekten im 3D Raum. Zudem sind Interaktionen in Echtzeit möglich. Bewegt sich das vom virtuellen Rahmen, eingerahmte reale Objekt, oder die Kamera selbst, verändert sich auch die Position des virtuellen Objektes. 

\begin{figure}[H]
	\centering
	\includegraphics[width=0.45\textwidth]{resources/fundamentals/example_camera_screen_ar}
	\caption{Beispiel an Digitalkamera. Kameraeinstellungen \cite{example_ar_camera}}
	\label{img:ar_camera_example}
\end{figure}

% Motivation
\cite{Azuma.1997} Durch das kombinieren von virtueller und physischer Welt, erweitert Augumented Reality die Wahrnehmung des Menschen. Die Motivation von AR ist, den Menschen durch das Einfügen
von digitalen Informationen in die physische Welt,Hinweise zu geben und Details zu aufzuzeigen die er mit seinen Sinnen sonst nicht unmittelbar wahrnehmen könnte. Diese Informationen sollen den Menschen 
bei der Verrichtung ihrer Aufgaben in der physischen Welt unterstützen.

% Anwendungsfelder von AR % Besonders passend für diese Arbeit sind Annotationen und Warung und Reperatur. Da diese sich besonders mit Interaktionen an Realen Objekten, meist Produkte befassen.
Azuma fasst in \cite{Azuma.1997}  Forschungen zu AR in sechs Anwendungsgebiete zusammen. Zur Visualisierung von Medizindaten, in der Wartung 
und Instandsetzung, Annotationen, für die Wegfindung für Roboter und für die Navigation von Militärflugzeugen. Beispielsweise können Annotationen 
verwendet werden um Informationen über den Inhalt von Regalen einzublenden während ein Nutzer durch ein Bibliothek läuft. % Füge hier vielleicht noch ein Beispiel dazu ein % Füge hier Verweis auf ein Artike als Fußnotel hinzu
Auch können Annotationen in AR verwendet werden um einzelne Bauelemente an komplexen Bauteilteilen zu identifizieren und Informationen über diese zu anzuzeigen. 
In der Wartung und Instandsetzung können Augemented Reality Anwendungen dabei helfen Instruktionen an komplexen Maschinen und Anlagen zu visualisieren welche sonst in 
Form von Text und Bildern vorliegen. So können virtuelle Replikate über die physischen Modelle gelegt, und so Schritt für Schritt Anleitungen direkt am physischen Produkt angezeigt werden. 
Durch Animationen können diese Anleitungen mit präziser gestaltet werden und zum Beispiel auch Informationen über die Richtung geben. 

Diese Systeme können heute zum Beispiel Unterunternehmen dabei helfen besser mit ihren Kunden zu kooperieren. In Kombination mit der Technologie Internet of Things (IOT) können Unternehmen,
zustandsbezogene Informationen zu Ihren Systemen bei Endkunden abrufen und proaktiv Ihre Kunden auf notwendige Wartungen aufmerksam zu machen. Wartungsanleitungen können dann direkt 
an den Analgen angezeigt werden.\footnote[2]{ https://www.ptc.com/-/media/Files/PDFs/Case-Studies/Howden-vuforia-studio-case-study-Feb-2019.pdf?la=en\&hash=6342841E1B6470C1F313295427398606 [letzter Zugriff: 25.06.2019]}

%Grundlegende Techniken
% file:///C:/Users/alibe/Desktop/papers/MarcusTönnis_einblicke_in_augmented_reality.pdf Seite 32
\cite{Tonnis2010} Für die Überlagerung der realen Welt mit virtuellen Objekten eignen sich aktuell zwei Display Techniken,  Optical See-Through und Video See-Through. 
Bei Optical See-Through kann der Nutzer direkt in die reale Welt blicken und Computer generierte Bilder werden auf ein halbdurchlässiges Spiegel eingeblendet (dieses wird als Combiner bezeichnet).
Diese Technik hat den Vorteil dass der Nutzer einen direkten Blick auf die reale Welt hat. Der Nachteil ist jedoch dass die reale Welt nicht zeitgleich mit virtuellen Objekten überlagert werden kann. 
Dadurch dass die Berechnung für die Positionsbestimmung und das Rendern der virtuellen Objekte Zeit in Anspruch nimmt, werden diese mit einer kleinen Verzögerung angezeigt. Dies kann auch 
wenn es nur sich nur um einige Millisekunden handelt zu einem so genannten Schwimmeffekt führen (en. lag). Mit der See Through Display Technik, wird die reale Welt dem Nutzer als ein Video 
gezeigt und mit virtuellen Objekten überlagert. Der Vorteil dieser Technik liegt darin, dass die Darstellung der realen Welt um die Zeit verzögert werden kann die benötigt wird um die virtuellen Objekte 
richtig zu positionieren und rendern. Dadurch werden die Nachteile der Optical-See-Through Technik kompensiert. Dass die reale Welt dem Nutzer verzögert angezeigt wird bringt jedoch den Nachteil 
dass Positionsänderungen von physischen im realen Welt befindenden Objekten oder die Änderung der Perspektive falls sich der Nutzer selbst bewegt verzögert angezeigt wird. Zudem wird mit 
dieser Technik je nach Auflösung der Kamera die reale Welt mit verringerter Qualität angezeigt. \cite[p.~368]{DieterSchmalstieg2016} Vor allem bei der Kommunikation mit anderen Personen können diese 
Nachteile zu Problemen führen. 

\section{Objekterkennung und- Verfolgung}

% Definition von Objekterkennung und Verfolgung

% Geschichte und Entwicklung

\subsection{Markerbasiertes Tracking}

% Begriffserklärung von Marker Trakting

% Anwendungsfelder von Marker Traking

\subsection{Markerloses Tracking}

% Begriffserklärung von Markerlosen Traking 

% Anwendungsfelder von Markerlosen Traking

\section{Situated Visualization}

Das zu konzipierende System soll durch den Einsatz von Augmented Reality, Kundenrückmeldungen zum Design von Produkten und das explorieren dieser Rückmeldungen ermöglichen. Damit dies gut gelingt 
ist ein gutes Verständnis von Situationsbewusste Visualisierung und Situationsbewusste Analyse (en. Situated Visualization/ Situated Analytics) erforderlich. 

\cite[p.~239]{DieterSchmalstieg2016} Ein großer Vorteil von Augmented Nutzeroberflächen Paradigma ist, dessen Fähigkeit, Situations, Aufgaben oder Nutzer-relevante Informationen anzeigen zu können. 
Diesen Vorteil zunutze zu machen ist jedoch sehr davon abhängig welche Informationen in AR, in welcher Form  präsentiert werden. Das Forschungsfeld Situated Visualization befasst mit der richtigen Interaktion und Präsentation
von computergenerierten Grafiken in der realen Szene mit physischen Gegenständen oder Personen. \cite[p.~188]{ElSayedNevenA.M.BruceH.ThomasRossT.Smith2015} Situated Visualization ist die Repräsentation von 
Daten welche in Bezug zur physischen Umgebung stehen. Die Bedeutungsbestimmung wird durch die Kombination von Visualisierung und dessen Beziehung zu der unmittelbaren Umgebung erreicht. \cite[p.~240]{DieterSchmalstieg2016} Abzugrenzen sind Visualisierungen welche zwar im 3D Raum präsentiert werden, jedoch keinen Bezug zu einer im dreidimensionalen Raum befindlichen Objekt, Person oder Aufgabe haben.

\cite[p.~192]{ElSayedNevenA.M.BruceH.ThomasRossT.Smith2015} \cite[p.~2]{WesleyWillettYvonneJansen} stellen folgendes konzeptionelle Model zur Situated Visualization vor:

\begin{figure}[H]
	\centering
	\includegraphics[width=0.5\textwidth]{resources/fundamentals/situated_visualization/spacially_situated_visualization_model.png}
	\caption{Konzeptionelles Model zu "Spatially-Situated Visualization" \cite{example_situated_visualization_concept}}
	\label{img:situated_visualization_concept}
\end{figure}

% spacially situated visualization
Dieses Model erweitert konventionelle Visualisierung logische Welt (oben) mit der physischen (realen) Welt unten. Die durchgängig dargestellten Pfeile zeigen den Informationsfluss zwischen den 
einzelnen Komponenten und die gestichelten Peile d und f  konzeptionelle Beziehungen. Der Informationsfluss beginnt bei den Rohdaten in der oberen linken Ecke der Darstellung. Die Rohdaten durchlaufen den 
Visualisierungs-Pipeline und werden in ein vom Menschen besser interpretierbare visuelle Form umgewandelt (a -> b). Die Visualisierungs-Pipeline wird weiter unten genauer vorgestellt. 
Die Beziehung zwischen logischer und physischer Welt wird mit zwei Beziehungen hergestellt (b und d).  Die physische Präsentation der Daten (b) stellt die Präsentation der Daten in visueller Form in der Realen Welt dar. 
Zum Beispiel könnte dies eine Auflistung, ein Diagramm oder ähnliches sein. Die zweite Beziehung ist die zwischen den Rohdaten und den physischen Referenten. Diese Beziehung ist konzeptionell da Datensätze sich auf mehrere unterschiedliche Referenten beziehen können. Manche Referenten produzieren selbst Daten (z. Bsp. mit Sensoren), dies ist jedoch nicht immer der Fall.Der Grad in wieweit der physische Referent und die physische Präsentation gleichzeitig wahrgenommen werden können hängt von der räumlichen Abstand zwischen diesen beiden ab. Ein Kaufinteressent könnte sich zum Beispiel Informationen zu einem Haus, Zuhause auf seinem Laptop ansehen und hätte keine Möglichkeit die Informationen zu dem Haus und das Haus selbst zur gleichen Zeit zu sehen. Er könnte aber auch vor dem Haus stehen und sich die Informationen zu dem Haus auf dem Bildschirm seines Smartphones anschauen. Oder die Informationen zu dem Haus könnten auf einem Schild auf dem Haus platziert sein. Je näher die physische Präsentation und der physische Referent räumlich zusammen sind desto stärker isst der Grad der räumlichen Situationsbewusstsein. 

%Physically- vs. Perceptually-Situated Visualizations 
\cite[p.~194]{ElSayedNevenA.M.BruceH.ThomasRossT.Smith2015}  da Distanzen jedoch relativ zu Größe von Objekten wahrgenommen werden, kann die physische und die wahrgenommene Distanz zwischen dem Physischen Referenten und der Physischen Präsentation stark voneinander abweichen. Wen beide Objekte zum Beispiel nur wenige cm groß sind sehr klein sind kann ein Abstand von einem Meter zum Beispiel sehr groß erscheinen, während der gleich Abstand für sehr großes Objekt sehr wie  ein Berg in einer Landschaftsansicht zum Beispiel sehr klein erscheint. 

%embedded visualisierung
\begin{figure}[H]
	\centering
	\includegraphics[width=0.5\textwidth]{resources/fundamentals/situated_visualization/embedded_visualization.png}
	\caption{Eingebettete Visualisierung \cite{example_embedded_visualization_concept}}
	\label{img:embedded_visualization}
\end{figure}

\cite[p.~195]{ElSayedNevenA.M.BruceH.ThomasRossT.Smith2015} Eingebettete Visualisierungen (Embedded Visualization) sind situationsbezogene Visualisierungen, welche sehr starken in die physische Umgebung integriert sind. 

Besteht ein Produkt, beispielsweise eine Brille, aus mehreren Einzelteile, (z. Bsp. Rechter Glas, Linker Glas, Rahmen, Nasenflügel, Schraube A usw.) und die Daten zu dieser Brille werden neben oder über der Brille visualisiert, gilt die Visualisierung situationsbewusst jedoch nicht als eingebettet.Werden hingegen Teile der Daten welche Einzelteile des physischen Gegenstands betreffen direkt an den Einzelteilen visualisiert, gilt die Visualisierung als eingebettet (embedded).

Abbildung \ref{img:embedded_visualization} zeigt eingebettete und nicht eingebettete situationsbewusste Visualisierungen. [Kim Marriott et. al Seite 202] zeigen am Beispiel eines Hauses als physischen Referenten, wie aus eingebettet Visualisierungen nicht eingebettet, und aus nicht eingebetten Visualisieungen, eingebettet Visualisierungen entstehen können. Wird wie am oberen Beispiel die Daten zu einem Haus in einer Visualisierung am Haus nahe des Hauses visualisiert, gilt die Visualisierung als "Situated" jedoch nicht eingebettet (a). Werden jedoch die Daten welche einzelne Einelemente des Hauses betreffen direkt am betreffenden Einzelelement visualisiert, gilt die Visualisierung als eingebettet (b). Betrachtet man jedoch eine Visualisierung zu mehreren Häusern (z. Bsp. ein Bezirk) und wird aus einer nicht eingebetten Visualisierung wie in a, eine eingebettet Visualisierung wie in (c) abgebildet. 

Eingebettete Visualisierung geht davon aus dass mehrere Teil-Visualisierungen zu jeweiligen physischen Referenten entsprechen. Befinden sich in einem Haus Beispielsweise mehrere Steckdosen und der Stromverbrauch 
für jede Steckdose wird jeweils direkt an jeder Steckdose direkt visualisiert, gilt die Visualisierung als eingebettet. Gibt es in dem Haus jedoch nur eine einige Steckdose, gilt die Visualisierung nicht mehr als
eingebettet.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.5\textwidth]{resources/fundamentals/situated_visualization/Illustration_situated_embedded_visualization.png}
	\caption{Illustration einer Situationsbewussten, eingebetteten oder physikalisierten Visualisierung \cite{Illustration_situated_embedded_visualization}}
	\label{img:Illustration_situated_embedded_visualization}
\end{figure}

Abbildung \ref{img:Illustration_situated_embedded_visualization} illustriert am Beispiel von Produkten welche in einem Regal, i

%Facsimiles

%Situated Analytics beschreiben

%[Schmalstieg und Höllerer] locally situated\ globally situated

% Information seeking mantra von Schneidermann 1996
% Falls die die Informationsmenge zu groß oder zu Komplex wird beschreiben Daniel A. Keim et. al: visual analytics mantra

\begin{table}[htbp]
\caption{Situatedness vs. Analytic Level}
	\begin{center}
		\begin{tabular}{|l|l|l|}
		\hline
		\textbf{Situatedness}& \textbf{Analytic Level Low} & \textbf{Analytic Level High}\\
		\hline
		\textbf{High } & Situation Awareness & Situated Analytics \\
		\hline
		\textbf{Low} & Information Displays/ Ambient Displays & Visual Analytics/ Traditional Analytics \\
		\hline
		\end{tabular}
	\end{center}
	\label{tab:categorycscw}
\end{table}


% Information seeking mantra nach Shneiderman


%Neven A. M. ElSayed et. all %  Situated Analytics has four primary elements: situated information, abstract information, augmented reality interaction, and analytical interaction

%Herrausforderungen: Unordnung duruch zu viele Daten (Überlagerung). Generell auch bei anderen visualisierungen. Durch limitierter Platz bei AR manchmal besonders verschlimmert. %Registrierungsfehler führen zur falschen platzierung von visualisierungen. 
% Störende\ Ungünstige Visualisierung. Auch wenn Registrierung theoretisch ganz fehlerfrei funtionieren würde, ungünstig sein und die Fähigkeit des Nutzers wichtige Informationen von nicht relevanten Informationen. 

% In folgendem werden Techniken für die Bewältigung dieser Herrausforderungen vorgestellt. 

Data Overlay 

% la

% Labeling und Annotationen


% 


\section{Computerunterstützte Kollaboration}

% Ziel des zu entwickelnden Systems, ist die erfolgreiche Kommunikation von Design Ideen durch den Endkunden. Kommunikation erfordert Kollaboration von Teilnehmern? Kunde <-> Kunde, Kunde <-> Hersteller zum Beispiel.  %Dazu schauen wir uns die computergestützte Collaboration näher an.

\cite[p.~362]{DieterSchmalstieg2016}In der computerunterstützten kooperativen Arbeit (en. Computer-supported cooperative work (CSCW)) ist eine Kategorisierung in Synchrone oder Asynchrone und Co-located oder Remote sehr verbreitet. Hierbei wird nach der zeitlichen (Synchron/ Asynchron) und nach der räumlichen (Co-located/ Remote ) Dimension der Kommunikation unterschieden. Betrachtet man die zeitliche Dimension, können mehrere Nutzer zur gleichen Zeit miteinander kommunizierender aber zur unterschiedlicher Zeit (also unabhängig voneinander) kommunizieren. In der räumlichen Dimension können Nutzer entweder am gleichen Ort miteinander kommunizieren oder entfernt voneinander sein. \cite[p.~188]{ElSayedNevenA.M.BruceH.ThomasRossT.Smith2015} zeigen eine weiger Form welche eine Mischform Remote und Co-located ist. Bei dieser Form von Kollaboration können 

\begin{table}[htbp]
\caption{Kategorisierung Computer unterstützter Kooperationssysteme in Bezug zu AR}
	\begin{center}
		\begin{tabular}{|l|ll|}
		\hline
		 & \textbf{Co-located} & \textbf{Remote}\\
		\hline
		\textbf{Synchronous} &  AR shared space & AR telepresence \\
		\textbf{Asynchronus} & AR annotating/ browsing (in-situ) & Generic sharing\\
		\hline
		\end{tabular}
	\end{center}
	\label{tab:categorycscw}
\end{table}

AR annotation\ browsing (in-situ). % laut Schmalstig ung Höllerer welche dieses Model von Rodden,  im Kontext von AR Anwendungen beschreiben, vergleichbar wie Graffitti.  

[Rodden seite 20]
% [Rodden seite 24] Co-authoring systems aim to support some of the most fundamental parts of cooperation by supporting the negotiation processes % for commenting %multiple users working on % [Rodden seite 24]store and forward and real-time communication systems. %notwendigkeit für unterscheidung zwischen private, public oder direkte nachrichten 
The general model adopted by these systems is that of asynchronous co-operation with each user working independently on a portion of the document. Reviews and comments are added to the document by annotating sections of the document. 

[SchmalstiegHöllerer16 Seite 362] Asychronous AR is less frequently utilized. The most important use case in this category is the annotation of a physical environment by one user and later in situ browsing or editing of the annotations by another user.
You might think of this application as a sort of virtual graffiti. 


% Immersive analytics seite 239

However, distributed asynchronous collaboration involves capturing input from people at different times and different placesandsocanprovidesomeuniquebenefits.Forexample,Benbunan-Fichet al. found that asynchronous collaboration can produce broader discussions and more complete reports from group discussions than their face-to-face counterparts [9]. Other benefits include enabling people to contribute whenever they have time to provide input [104], they can work on the part of the problem that they feel most qualified to address [129], and can combine information from a variety of sources [52].


\section{Usability}

% Ziel der Arbeit ist ein Weg zu finden um effektiv und effizient Produktdesignbeschreibungen an Produkten zu zeigen mit einsatz von Augmented Realiy und verschiedene Techniken zu 
%vergleichen. Dafür muss ein besonderer Fokus auf die Usablity gelegt werden. Daher hier usability...
Einen besonderen Fokus soll diese Arbeit auf die Usability legen. Daher wird in folgendem Abschnitt die Begriffsdefinition von Usablity näher beleuchtet, es werden einige 
gängige Methoden für die nutzenorientierte Gestaltung und Entwicklung von Systemen vorgestellt und abschließend Methoden für Usability Tests und Evaluierung erläutert. 

\subsection{Was ist Usability?}

% Begiffserklärung von Usability
In der Norm-reihe ISO 9241 welches als ein internationaler Standard, Richtlinien für die Gestaltung von Mensch-Computer-Interaktionen beschreibt, wird im ISO Norm 9241-11,  Usability wie folgt definiert:

"das Ausmaß, in dem ein Produkt durch bestimmte Benutzer in einem bestimmten Nutzungskontext genutzt werden kann um bestimmte Ziele effektiv, effizient und zufriedenstellend zu erreichen."

% Usablity nicht nur Gestaltung der Nutzeroberfläche
\cite{MichaelRichter2016; MaryBethRossonJohnM.CarrollDianeD.Cerra2002} Usablity wird  oft als ein Qualitätskriterium für die Gestaltung der Benutzerschnittstelle verstanden. Dies ist jedoch nicht ganz richtig.

%Die Benutzbarkeit eines Systems muss im Kontext seiner Verwendung beurteilt werden.[Michael Richter, Markus Flückiger]
Dass die Usability eines Systems nach dessen Nutzungskontext zu beurteilen ist verdeutlichen \cite{MichaelRichter2016} an einem konkreten Beispiel für die Erfassung 
von Kurznachrichten (SMS) mit dem Aufkommen von Mobiltelefonen.  Bevor Smartphones mit Touch-Displays verbreitet waren, hatten Mobiltelefone oft rein numerische Tastaturen sodass, das Erfassen 
von Textnachrichten über die Nutzung der numerischen Tasten erfolgen musste. Indem zum Beispiel in kurzen Zeitabständen zwei mal auf die Taste "2" gedrückt wurde, wurde zu Beispiel der Buchstabe ``B`` eingegeben. 
Diese Eingabemethode wurde oftmals von vielen Nutzern als umständlich empfunden. Jedoch konnte auf diese Weise effizient und zufriedenstellend die die Aufgabe, eine Kurznachricht zu erfassen erfüllt werden. 
Zudem war diese Methode einfach zu erlernen und einprägsam. Somit wies diese Ansatz eine hohe Usablity auf. 

% Usablity nicht nur User friendly
\cite{Nielsen1994,RexHartson2012} Oft wird Usablity auf die Eigenschaft eines Systems reduziert besonders benutzerfreundlich (en. User- friendly) zu sein. Der Begriff Usabliy umfasst jedoch mehr Aspekte. 

\cite{Nielsen1994} Mit dem Begriff "User- friendly" als Synonym für Usablity würde impliziert werden dass die Bedürfnisse von Benutzern mit nur einer einzigen Eigenschaft eines Systems beschrieben werden kann. 
In der Realität haben jedoch unterschiedliche Nutzer, verschiedenartige Bedürfnisse. Ein System welches zu einem Benutzer freundlich erscheint, könnte unter Umständen von einem anderen Nutzer als lästig empfunden werden.

% Eine Teilmenge der Systemazeptanz 
Nielsen Unterteilt Akzeptanzkriterien für ein Systems in soziale und praktische Kriterien.

Soziale bzw. ethische Akzeptanzkriterien sind solche, welche  die Nutzer von der Nutzung eines Systems abhalten, selbst wenn praktische Akzeptanzkriterien sehr gut erfüllt sind. 
\cite[p.~285]{Spiekermann2016} führt hierzu ein gutes Beispiel für ein solches Kriterium auf. Sie beschreibt am Beispiel eines Körperscanners an Flughäfen, dass trotzt  Berücksichtigung vieler 
praktischer Aspekte wie Ergonomie und trotz der effizienten und effektiven Aufgabenerfüllung ein solches System wenig Akzeptanz von den Nutzern haben kann. Beispielsweise fühlten sich Passagiere 
unangenehm wenn der Bildschirm auf welchem die nackten Umrisse ihrer Körper zu sehen war so platziert war dass andere Passagiere es auch sehen konnten.  
\footnote[3]{https://www.wired.com/2013/01/tsa-abandons-nude-scanners/ [Zuletzt aufgerufen am: 26.06.2019]}

Als praktische Kriterien führt er Eigenschafen wie Kosten, Kompatibilität, Zuverlässigkeit sowie Nutzbarkeit auf. Die Eigenschaft Benutzbarkeit teilt er in die Eigenschaften Nützlichkeit (en. Utility) und Gebrauchstauglichkeit (en. Usability) auf. Unter Utility ist zu verstehen ob ein System mit den Funktionalitäten die es bereitstellt prinzipiell in der Lage ist, die Aufgabe zu erfüllen wozu sie konzipiert wurden.

Die Eigenschaft Geruchstauglichkeit gliedert er in folgende fünf Teileigenschaften: 

\begin{itemize}
	\item Einfach zu erlernen.
	\item Effizient in der Nutzung.
	\item Leicht zu merken. (Ein Nutzer welcher das System einmal verwendet hat, sollte in der Lage sein nach einer längeren Pause das System zu nutzen ohne es erneut erlernen zu müssen.)
	\item Wenig Fehler. (Das System sollte zu möglichst wenig Fehler während der Nutzung führen. Im Falle das Fehler auftritt, sollte es möglich sein dass sich das Systems von diesem Fehler erholt und die Nutzung fortgeführt werden kann.)
	\item Subjektive Zufriedenstellung (Das System sollte angenehm zu nutzen sein. So dass Nutzer auch subjektiv zufriedengestellt werden während sie das System nutzen.)
\end{itemize}

%7 Kritärien nach ISO 9241 Teil 110 - ASSEFIL) 
Im ISO Norm  9241-110 sind diese Kriterien, als Grundsätze zur Dialoggestaltung wie folgt aufgeführt:

\begin{itemize}
	\item Aufgabenangemessenheit \footnote[4]{Beispiele für Aufgabenangemessenheit ab Seite 5: https://www.medien.ifi.lmu.de/lehre/ss16/id/ISO\_9241-10.pdf [zuletzt aufgerufen am: 26.06.2019]}
	\item Selbstbeschreibungsfähigkeit
	\item Steuerbarkeit
	\item Erwartungskonformität
	\item Fehlertoleranz
	\item Individualisierbarkeit
	\item Lernförderlichkeit
\end{itemize}

% Warum ist es wichtig?

%TODO: Folgerung für diese Arbeit!!!

\subsection{Usablity Engineering}

\cite{MichaelRichter2016} Im laufe der Zeit haben sich verschiedene Fachrichtungen (wie z. Bsp: Human Computer Interaction (HCI), Human Factors, Interaction Design, Usability Engineering, 
User centered Design (UCD), User Experience (UX) und Design Thinking)  entwickelt welche nutzenorientierte Methoden für die Entwicklung von Technologien und neuen Anwendungen verfolgen. 

% Usablity Engineering
\cite{MaryBethRossonJohnM.CarrollDianeD.Cerra2002} Als eines dieser Fachrichtungen wurde die Fachrichtung Usablity Engineering von Usability Fachleuten bei Equipment Corparation ins Leben gerufen.  
Der Begriff Usability Engineering steht für die Konzeption und Techniken für die Planung, Verifizierung und Abdeckung von Usability Zielen eines Systems. Das Ziel von Usability Enginieering ist, 
messbare Usability Ziele in den frühen Phasen des Softwareentwicklungsprozesses zu definieren und einen Rahmen zu schaffen diese Ziele im laufe der Entwicklung stetig überprüfen zu können 
um sicherstellen zu können dass diese erreicht werden.

Nielsen beschreibt in \cite{Nielsen1994} folgende Phasen im Lebenszyklus von Projekten mit Software Engenieering Methoden.

Analyse der Nutzer, dessen Aufgaben und Ziele:  

In dieser Phase der Usability Engineering werden alle Nutzer identifiziert, die mit dem System in Berührung kommen werden. Als Nutzer sollten in alle Personen verstanden werden welche mit dem 
System oder mit Artefakten des Systems in Berührung kommen werden. Dies können Personen beinhalten welche das System installieren, konfigurieren, warten, administrieren oder Endkunden oder 
Kunden die das System selbst nie sehen werden jedoch Ergebnisse von dem System erhalten werden.  In einigen Fällen ist es einfacher potenzielle Nutzer von einem System zu identifizieren und deren 
Charakteristiken zu studieren. Zum Beispiel für ein Produkte die in einer bestimmten Abteilung eines bestimmten Unternehmens eingesetzt werden soll. Schwieriger kann es hingegen für Produkte werden 
welche von einer breiteren Menge von Nutzern genutzt werden soll.Es sollten Eigenschaften von Nutzern studiert werden welche für die Nutzen des Systems relevant sein könnten wie zum Bsp. 
Erfahrung von solchen Systemen und Endgeräten, Bildungsstand, Alter. etc. Dieser Schritt ist wichtig um die Lernfähigkeit von Nutzern besser einschätzen zu können und so Kriterien für die Komplexität der 
Nutzeroberfläche zu bestimmen.

% task analysis
Sobald die Nutzer identifiziert und dessen Eigenschaften und Bedürfnisse analysiert wurden, werden die Ziele und Aufgaben der Nutzer analysiert. Wie bewältigen die  Nutzer aktuell Aufgaben um 
ihre Ziele zu erreichen. Hierbei sollte beobachtet werden welche Informationen die Nutzer benötigen, welche Ausnahme oder Not Situationen  auftreten und wie die Nutzer in diesen Situationen handeln. 
Es sollte beobachtet werden ob die Nutzer das aktuell verwendete System in irgendeiner  weise umgehen (en. Workarounds anwenden). Zudem sollten die Begrifflichkeiten notiert werden welche der 
Nutzer verwendet im Bezug auf die zu lösende Aufgabe verwendet.  Diese können später als eine Quelle für Metapher bei der Gestaltung der Nutzeroberfläche verwendet werden. 

% functional analysis
Im nächsten Schritt werden die benötigten Funktionalitäten des neuen Systems analysiert und Möglichkeiten erforscht wie diese mit dem neuen System erzielt werden können. 
Es ist wichtig dass in diesem Schritt die Mögliche Umsetzung der Funktionalitäten sich nicht ausschließlich an Lösungen von bereits bestehenden Systemen orientiert sondern 
bessere geeignete Umsetzungsmöglichkeiten erkundet werden.

% evolution of the user
Zuletzt werden in dieser Phase Möglichkeiten erforscht wie sich das Nutzungsverhalten der Nutzer in Zukunft mit der Nutzung des neuen Systems entwickeln könnte. Dieser Schritt wird  
gemacht um das neue System flexibel genug und offen für neue Anforderungen welche in der Zukunft auftreten können gestalten zu können.

Analyse bestehender Produkte: 

In dieser Phase werden bestehende Produkte analysiert. Diese können für die Konzeption des neuen Systems als Prototypen dienen. Da bestehende Systeme vollständig 
umgesetzte Funktionalitäten beinhalten, können diese einfach getestet werden.    
Diese Systeme können heuristisch evaluiert werden, es können Nutzer Studien durchgeführt werden oder es kann eine vergleichende Analyse durchgeführt werden falls mehrere Systeme zur 
Verfügung stehen. Auf Basis der Informationen die, in der Phase "Kenne deiner Nutzer" zusammengetragen wurden, wird in dieser Phase analysiert wie gut die  Funktionalitäten und Interaktionstechniken 
bestehender Systeme die Nutzer bei der Umsetzung ihrer Aufgaben unterstützen. Das Lesen von technischen Produktrezessionen kann in dieser Phase auch hilfreiche Informationen über bestehende Systeme geben. 

Usablity Ziele setzen: 

Wie im Abschnitt "Was ist Usability" beschrieben, setzt sich die Usability eines Systems nicht nur aus einer Eigenschaft zusammen sondern gliedert sich in mehrerer Eigenschaften wie Erlernbarkeit, Fehlertoleranz etc. auf. 
Oft ist es nicht möglich alle Usablity Kriterien mit gleicher Gewichtung zu priorisieren. In dieser Phase werden auf Grundlage der Analyse von Nutzern und deren Aufgaben und Zielen, Prioritäten für Usability Kriterien definiert. 

Dafür werden die Usablity Kritärien operationalisiert und in messbaren Zielen ausgedrückt. Meistens werden Messintervalle für angestrebte Werte, für minimal zu erreichende Werte und theoretisch optimale Werte definiert. 
Als minimal zu erreichende Werte sind, gelten der Regel Werte welche aktuell mit dem System erreicht werden kann. Usability Ziele für neue Versionen von bestehenden Systemen oder für Systeme für welche vergleichbare andere 
Systeme existieren, festzulegen ist deutlich einfacher als für neue Systeme wozu keine Vergleichswerte vorliegen. Ein Vorgehen für solche Systeme ist, einige mit dem System zu lösende Aufgaben zu definieren und mehrere Usablity Spezialisten nach realistischen Werten zu fragen welche erzielt werden könnten.

Prototypen:

% Vertikale/ Horizontale

%Warum? Vorteile?

% Prototyping für 3D oberflächen?

% Noch weitere aber hier nur kurz. 

\subsection{Personas, Szenarien und Use Cases}

% Personas

% Szenarios

% Use Cases

\subsection{Usablity Tests und Evaluirung}

\section{Open Innovation}

% Definition von Open Innovatin vgl. zu Closed Innovation

% Anwendungsfelder

% Vorteile 

% Probleme
